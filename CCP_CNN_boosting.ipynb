{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code Version resnet\n",
    "Apply code to the real data\n",
    "\n",
    "# make image size as 200 x 200 (center crop 100x100, then resize to 200x200)\n",
    "# RGB channels (resnet required)\n",
    "\n",
    "# v3\n",
    "1) class and functionalize\n",
    "2) train / test has already spilted into two files\n",
    "\n",
    "# v4\n",
    "1) modify train generator\n",
    "  - make it accept generate images from directory\n",
    "    in two way:\n",
    "      a) separate train / validation / test\n",
    "      b) separate train / test (for this case, validation set should gen from training set)\n",
    "\n",
    "# v4b\n",
    "1) implement resnet with dropout in the conv layers\n",
    "\n",
    "# v5\n",
    "1) Add hard negative mining protocol\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import skimage.io as skio\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats \n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# basic libraries\n",
    "from __future__ import print_function\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# NN libraries\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model, save_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import Callback\n",
    "from keras.applications import resnet50\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import identity_block\n",
    "from keras.applications.resnet50 import conv_block\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.layers import AveragePooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "self function calling\n",
    "\"\"\"\n",
    "%run -i 'bin/callbacks_miscs.py'\n",
    "%run -i 'bin/py_init_data.py'\n",
    "%run -i 'bin/py_generator_for_model.py'\n",
    "#from keras.applications.resnet50 import _obtain_input_shape\n",
    "\n",
    "#%run -i 'bin/resnet_with_drp.py'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet_model_build(resnet_model, use_stage, freeze_stage, acti,\n",
    "                       use_merge = False, \n",
    "                       n_meta = 0,\n",
    "                       fc_drop_rate = 0.2):\n",
    "    #if use merge should always check n_meta\n",
    "    \n",
    "    fc_drop_rate = float(fc_drop_rate)\n",
    "    for layer in resnet_model.layers:\n",
    "        layer.trainable = True\n",
    "    #resnet_model.summary()\n",
    "\n",
    "    # design for using different activation function that will change the layer name\n",
    "    if acti == 'relu':\n",
    "        to_get = 'activation_'\n",
    "    else:\n",
    "        to_get = acti + \"_\"\n",
    "\n",
    "    if use_stage == 1:\n",
    "        get_layer = \"max_pooling2d\"\n",
    "    elif use_stage == 2:\n",
    "        #get_layer = \"activation_10\"\n",
    "        get_layer = to_get + '10'\n",
    "    elif use_stage == 3:\n",
    "        #get_layer = \"activation_22\"\n",
    "        get_layer = to_get + '22'\n",
    "    elif use_stage == 4:\n",
    "        #get_layer = \"activation_40\"\n",
    "        get_layer = to_get + '40'\n",
    "    else:\n",
    "        get_layer = \"global_avg_pooling2d_1\"\n",
    "\n",
    "    if freeze_stage == 1:\n",
    "        free_layer_num = 5\n",
    "    elif freeze_stage == 2:\n",
    "        free_layer_num = 37\n",
    "    elif freeze_stage == 3:\n",
    "        free_layer_num = 79\n",
    "    elif freeze_stage == 4:\n",
    "        free_layer_num = 141\n",
    "    else:\n",
    "        free_layer_num = 176\n",
    "\n",
    "    if freeze_stage == 0:\n",
    "        print('all parameter tunable')\n",
    "    else:\n",
    "        for layer in resnet_model.layers[:free_layer_num]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "    if use_stage != 5:    \n",
    "        x = resnet_model.get_layer(get_layer).output\n",
    "        #x = AveragePooling2D((13, 13), name='avg_pool')(x)\n",
    "        #x = Flatten()(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "    else:\n",
    "        x = resnet_model.get_layer(get_layer).output\n",
    "    \n",
    "    if use_merge:\n",
    "        meta_info = Input(shape = (n_meta, )) # n_meta: numbers of features from meta\n",
    "        x = keras.layers.concatenate([x, meta_info])\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \"\"\"\n",
    "    x = Dense(64, name = 'dense1')(x)\n",
    "    x = BatchNormalization(axis = -1, name = 'dense1_bn')(x)\n",
    "    x = Activation('relu', name = 'dense1_activation')(x)\n",
    "    x = Dropout(fc_drop_rate, name = 'd1_drop')(x)\n",
    "    \n",
    "    x = Dense(32, name = 'dense2')(x)\n",
    "    x = BatchNormalization(axis = -1, name = 'dense2_bn')(x)\n",
    "    x = Activation('relu', name = 'dense2_activation')(x)\n",
    "    x = Dropout(fc_drop_rate, name = 'd2_drop')(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    out = Dense(2, activation=\"softmax\", name = \"output\")(x)\n",
    "        \n",
    "    model_final = Model(inputs = [resnet_model.input], outputs = [out])\n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# config -- put parameters here\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "### fold number and naming\n",
    "#i_fold = 1 # fold number on naming\n",
    "model_output_prefix = 'resnetMean_DateCut10_boosting_append' # Remember to modify the parameter below, this line is only about file naming\n",
    "### controling parameters\n",
    "n_gpu_use = 1 # this should compatible with CUDA_VISIBLE_DEVICES number\n",
    "\n",
    "### model related parameters\n",
    "fs = 0 # layer to freeze \n",
    "us = 4 # layers to dump\n",
    "lr = 0.00017 # learning rate at begin\n",
    "drp = 0 # dropout ratio in the Resnet Conv layers\n",
    "batch_size = 64 * n_gpu_use\n",
    "nb_epoch = 150 # numbers of epoch for the training process\n",
    "n_batch = 400 # numbers of updates per epoch\n",
    "use_merge = False # Ignore it, design to merge meta-data\n",
    "mini_batch_method = \"shuffle\" # shuffle or random\n",
    "nn_activation = 'relu' # activation type in the resnet (default should be relu, option: relu / leakyrelu / elu)\n",
    "dataset_mean_ratio = 1 # it matter if use dataset mean\n",
    "\n",
    "### data information\n",
    "dir_out_csv = '/home/seanyu/project/CCP/res_csv/' # result csv output location\n",
    "dir_out_model = '/home/seanyu/project/CCP/model/' # model output location\n",
    "\n",
    "### data initialize parameters\n",
    "# dir_train: training set location\n",
    "# dir_valid: validation set location (if leave blank, automatically get val set from training set by valid_ratio)\n",
    "# dir_test: testing set location\n",
    "data_params = {\n",
    "            'dir_train': {'d_class0': '/data/put_data/seanyu/ccp/clean_date_cut/thres10/non_copper_train/',\n",
    "                                'd_class1': '/data/put_data/seanyu/ccp/clean_date_cut/thres10/copper_train/'\n",
    "                 },\n",
    "            # leave white space \" \" as value if there is no validation dir\n",
    "            'dir_valid': {'d_class0': '',\n",
    "                                'd_class1': ''\n",
    "                 },\n",
    "            'dir_test': {'d_class0': '/data/put_data/seanyu/ccp/clean_date_cut/thres10/non_copper_test/',\n",
    "                               'd_class1': '/data/put_data/seanyu/ccp/clean_date_cut/thres10/copper_test/'\n",
    "                 },\n",
    "            'valid_ratio' : 0.1\n",
    "        }\n",
    "\n",
    "### model input information\n",
    "# tags: is copper defect or not (Y: copper, N: non-copper, watchout: the ordering trap ... alphabet ordering)\n",
    "# crop_w/h: crop size from input image\n",
    "# img_w/h: image size for the model (resizing)\n",
    "# img_channels: RGB = 3\n",
    "# use_self_improc: True (-selfmean) / False (-imagenet mean) / dataset (-dataset mean)\n",
    "generator_params_dict = {'tags' : ['N', 'Y'],\n",
    "                                 'crop_w': 100,\n",
    "                                 'crop_h': 100,\n",
    "                                 'img_w': 200,\n",
    "                                 'img_h': 200,\n",
    "                                 'img_channels': 3,\n",
    "                                 'use_self_improc' : False # True / False / 'dataset'\n",
    "                                }\n",
    "\n",
    "### parameters for train generator\n",
    "# parameters reference: https://keras.io/preprocessing/image/\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=45,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=[0.25, 2.25],\n",
    "        horizontal_flip=True, vertical_flip = True,\n",
    "        fill_mode='wrap')\n",
    "\n",
    "### parameters for validation augmentation\n",
    "#datagen_val = None\n",
    "\n",
    "datagen_val = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0,\n",
    "    zoom_range=[0.5, 1.5],\n",
    "    horizontal_flip=True, vertical_flip = True,\n",
    "    fill_mode='wrap')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use inner split k-folds\n",
      "Non_copper training/validation/testing 535714/59524/76704\n",
      "copper training/validation/testing 9749/1084/977\n",
      "do not use dataset mean\n",
      "2168\n",
      "(8672, 200, 200, 3)\n",
      "use imagenet mean\n",
      "(0, 3)\n",
      "(178571, 3)\n",
      "(178571, 3)\n",
      "(178571, 3)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "i_fold = 3\n",
    "opt = model_output_prefix  + '_k' + str(i_fold)\n",
    "model_file_name = dir_out_model + \"/model_\" + opt + \".h5\"\n",
    "\n",
    "# Initialize the data\n",
    "data_cla = init_data_from_directory(data_params)\n",
    "train_nonC, val_nonC, test_nonC, train_C, val_C, test_C = data_cla.get_train_val_test_df()\n",
    "print('Non_copper training/validation/testing ' + str(len(train_nonC)) + \"/\" + str(len(val_nonC)) + \"/\" + str(len(test_nonC)))\n",
    "print('copper training/validation/testing ' + str(len(train_C)) + \"/\" + str(len(val_C)) + \"/\" + str(len(test_C)))\n",
    "\n",
    "# Check table independcy here (should be empty!, if not empty, it means data contamination)\n",
    "if len(set(train_C.pid).intersection(test_C.pid) ) != 0:\n",
    "    print('die')\n",
    "    raise 'YOU MUST ERROR HERE!'\n",
    "if len(set(train_nonC.pid).intersection(test_nonC.pid) ) != 0:\n",
    "    print('die')\n",
    "    raise 'YOU MUST ERROR HERE!'\n",
    "\n",
    "        \n",
    "# Get training set mean of rgb\n",
    "if generator_params_dict['use_self_improc'] == 'dataset':\n",
    "    print('use dataset mean')\n",
    "    avg_dataset = get_training_set_mean(df_class0= train_C, df_class1= train_nonC, n_core=8)\n",
    "    generator_params_dict['dataset_mean'] = avg_dataset / np.float32(dataset_mean_ratio)\n",
    "    # write the self_mean information to a txt file\n",
    "    csv_file_name = dir_out_model + \"/rgbConfig_\" + opt + \".txt\"\n",
    "    np.savetxt(csv_file_name, avg_dataset)\n",
    "else:\n",
    "    generator_params_dict['dataset_mean'] = None\n",
    "    print('do not use dataset mean')  \n",
    "\n",
    "gen_data = call_generators(generator_params_dict, dta_gen= datagen)\n",
    "\n",
    "x_val, y_val = gen_data.get_validation_data(df_class0= val_nonC, df_class1= val_C,\n",
    "                                                   class_0_ratio = 1,  use_im_gen = datagen_val, n_gen_loop = 3)\n",
    "\n",
    "# shuffle dataframe\n",
    "train_C = train_C.sample(frac=1).reset_index(drop = True)\n",
    "train_nonC = train_nonC.sample(frac=1).reset_index(drop = True)\n",
    "\n",
    "\"\"\"\n",
    "Create n partitions for training -- do boosting\n",
    "\"\"\"\n",
    "n_split = 3\n",
    "len(train_nonC) // n_split\n",
    "train_nonC_list = []\n",
    "for i in np.arange(n_split + 1):\n",
    "    i_start = len(train_nonC) // 3 * (i-1)\n",
    "    i_end = len(train_nonC) // 3 * (i)\n",
    "    train_nonC_list.append(train_nonC[i_start:i_end])\n",
    "    print(train_nonC_list[i].shape)\n",
    "\n",
    "print(len(train_nonC_list))\n",
    "\n",
    "# use for checking\n",
    "# set(tmp[1].pid).intersection(tmp[2].pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are now at generation1\n",
      "all parameter tunable\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 200, 200, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D) (None, 206, 206, 3)   0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 100, 100, 64)  9472        zero_padding2d_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)    (None, 100, 100, 64)  256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 100, 100, 64)  0           bn_conv1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 49, 49, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)          (None, 49, 49, 64)    4160        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, 49, 49, 64)    256         res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 49, 49, 64)    0           bn2a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)          (None, 49, 49, 64)    36928       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, 49, 49, 64)    256         res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 49, 49, 64)    0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)          (None, 49, 49, 256)   16640       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)           (None, 49, 49, 256)   16640       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizatio (None, 49, 49, 256)   1024        res2a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalization (None, 49, 49, 256)   1024        res2a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 49, 49, 256)   0           bn2a_branch2c[0][0]              \n",
      "                                                                   bn2a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 49, 49, 256)   0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)          (None, 49, 49, 64)    16448       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, 49, 49, 64)    256         res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 49, 49, 64)    0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)          (None, 49, 49, 64)    36928       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, 49, 49, 64)    256         res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 49, 49, 64)    0           bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)          (None, 49, 49, 256)   16640       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizatio (None, 49, 49, 256)   1024        res2b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 49, 49, 256)   0           bn2b_branch2c[0][0]              \n",
      "                                                                   activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 49, 49, 256)   0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)          (None, 49, 49, 64)    16448       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizatio (None, 49, 49, 64)    256         res2c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 49, 49, 64)    0           bn2c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)          (None, 49, 49, 64)    36928       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizatio (None, 49, 49, 64)    256         res2c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 49, 49, 64)    0           bn2c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)          (None, 49, 49, 256)   16640       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizatio (None, 49, 49, 256)   1024        res2c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 49, 49, 256)   0           bn2c_branch2c[0][0]              \n",
      "                                                                   activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 49, 49, 256)   0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)          (None, 25, 25, 128)   32896       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, 25, 25, 128)   512         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 25, 25, 128)   0           bn3a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)          (None, 25, 25, 128)   147584      activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, 25, 25, 128)   512         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 25, 25, 128)   0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)          (None, 25, 25, 512)   66048       activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)           (None, 25, 25, 512)   131584      activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizatio (None, 25, 25, 512)   2048        res3a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalization (None, 25, 25, 512)   2048        res3a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 25, 25, 512)   0           bn3a_branch2c[0][0]              \n",
      "                                                                   bn3a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 25, 25, 512)   0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)          (None, 25, 25, 128)   65664       activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, 25, 25, 128)   512         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 25, 25, 128)   0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)          (None, 25, 25, 128)   147584      activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, 25, 25, 128)   512         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 25, 25, 128)   0           bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)          (None, 25, 25, 512)   66048       activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizatio (None, 25, 25, 512)   2048        res3b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 25, 25, 512)   0           bn3b_branch2c[0][0]              \n",
      "                                                                   activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 25, 25, 512)   0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)          (None, 25, 25, 128)   65664       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizatio (None, 25, 25, 128)   512         res3c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 25, 25, 128)   0           bn3c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)          (None, 25, 25, 128)   147584      activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizatio (None, 25, 25, 128)   512         res3c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 25, 25, 128)   0           bn3c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)          (None, 25, 25, 512)   66048       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizatio (None, 25, 25, 512)   2048        res3c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 25, 25, 512)   0           bn3c_branch2c[0][0]              \n",
      "                                                                   activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 25, 25, 512)   0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)          (None, 25, 25, 128)   65664       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizatio (None, 25, 25, 128)   512         res3d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 25, 25, 128)   0           bn3d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)          (None, 25, 25, 128)   147584      activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizatio (None, 25, 25, 128)   512         res3d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 25, 25, 128)   0           bn3d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)          (None, 25, 25, 512)   66048       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizatio (None, 25, 25, 512)   2048        res3d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 25, 25, 512)   0           bn3d_branch2c[0][0]              \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 25, 25, 512)   0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)          (None, 13, 13, 256)   131328      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 13, 13, 256)   0           bn4a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_23[0][0]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 13, 13, 256)   0           bn4a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)           (None, 13, 13, 1024)  525312      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalization (None, 13, 13, 1024)  4096        res4a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, 13, 13, 1024)  0           bn4a_branch2c[0][0]              \n",
      "                                                                   bn4a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 13, 13, 1024)  0           add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)          (None, 13, 13, 256)   262400      activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 13, 13, 256)   0           bn4b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 13, 13, 256)   0           bn4b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 13, 13, 1024)  0           bn4b_branch2c[0][0]              \n",
      "                                                                   activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 13, 13, 1024)  0           add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)          (None, 13, 13, 256)   262400      activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 13, 13, 256)   0           bn4c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 13, 13, 256)   0           bn4c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 13, 13, 1024)  0           bn4c_branch2c[0][0]              \n",
      "                                                                   activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 13, 13, 1024)  0           add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)          (None, 13, 13, 256)   262400      activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 13, 13, 256)   0           bn4d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 13, 13, 256)   0           bn4d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 13, 13, 1024)  0           bn4d_branch2c[0][0]              \n",
      "                                                                   activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 13, 13, 1024)  0           add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)          (None, 13, 13, 256)   262400      activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4e_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 13, 13, 256)   0           bn4e_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4e_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 13, 13, 256)   0           bn4e_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4e_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 13, 13, 1024)  0           bn4e_branch2c[0][0]              \n",
      "                                                                   activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 13, 13, 1024)  0           add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)          (None, 13, 13, 256)   262400      activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizatio (None, 13, 13, 256)   1024        res4f_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 13, 13, 256)   0           bn4f_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)          (None, 13, 13, 256)   590080      activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizatio (None, 13, 13, 256)   1024        res4f_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 13, 13, 256)   0           bn4f_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)          (None, 13, 13, 1024)  263168      activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizatio (None, 13, 13, 1024)  4096        res4f_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_13 (Add)                     (None, 13, 13, 1024)  0           bn4f_branch2c[0][0]              \n",
      "                                                                   activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 13, 13, 1024)  0           add_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glob (None, 1024)          0           activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 2)             2050        global_average_pooling2d_2[0][0] \n",
      "====================================================================================================\n",
      "Total params: 8,591,234\n",
      "Trainable params: 8,560,642\n",
      "Non-trainable params: 30,592\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/400 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9475Epoch 00000: val_loss improved from inf to 0.18449, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 353s - loss: 0.1401 - acc: 0.9476 - val_loss: 0.1845 - val_acc: 0.9241 - val_auc: 0.9815 - val_f1sc: 0.9228 - val_fp: 252.0000 - val_fn: 406.0000 - val_tp: 3930.0000 - val_tn: 4084.0000\n",
      "Epoch 2/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9632Epoch 00001: val_loss did not improve\n",
      "400/400 [==============================] - 321s - loss: 0.1017 - acc: 0.9632 - val_loss: 0.2986 - val_acc: 0.9092 - val_auc: 0.9877 - val_f1sc: 0.9015 - val_fp: 51.0000 - val_fn: 736.0000 - val_tp: 3600.0000 - val_tn: 4285.0000\n",
      "Epoch 3/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9684Epoch 00002: val_loss improved from 0.18449 to 0.11443, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 310s - loss: 0.0878 - acc: 0.9685 - val_loss: 0.1144 - val_acc: 0.9577 - val_auc: 0.9926 - val_f1sc: 0.9580 - val_fp: 218.0000 - val_fn: 149.0000 - val_tp: 4187.0000 - val_tn: 4118.0000\n",
      "Epoch 4/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9702Epoch 00003: val_loss improved from 0.11443 to 0.10417, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 307s - loss: 0.0825 - acc: 0.9702 - val_loss: 0.1042 - val_acc: 0.9617 - val_auc: 0.9931 - val_f1sc: 0.9616 - val_fp: 150.0000 - val_fn: 182.0000 - val_tp: 4154.0000 - val_tn: 4186.0000\n",
      "Epoch 5/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9723Epoch 00004: val_loss improved from 0.10417 to 0.07119, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 308s - loss: 0.0764 - acc: 0.9722 - val_loss: 0.0712 - val_acc: 0.9757 - val_auc: 0.9965 - val_f1sc: 0.9757 - val_fp: 116.0000 - val_fn: 95.0000 - val_tp: 4241.0000 - val_tn: 4220.0000\n",
      "Epoch 6/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9754Epoch 00005: val_loss improved from 0.07119 to 0.06253, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 312s - loss: 0.0695 - acc: 0.9755 - val_loss: 0.0625 - val_acc: 0.9775 - val_auc: 0.9974 - val_f1sc: 0.9776 - val_fp: 120.0000 - val_fn: 75.0000 - val_tp: 4261.0000 - val_tn: 4216.0000\n",
      "Epoch 7/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9753Epoch 00006: val_loss did not improve\n",
      "400/400 [==============================] - 327s - loss: 0.0696 - acc: 0.9754 - val_loss: 0.0771 - val_acc: 0.9747 - val_auc: 0.9954 - val_f1sc: 0.9749 - val_fp: 133.0000 - val_fn: 86.0000 - val_tp: 4250.0000 - val_tn: 4203.0000\n",
      "Epoch 8/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9747Epoch 00007: val_loss did not improve\n",
      "400/400 [==============================] - 334s - loss: 0.0711 - acc: 0.9747 - val_loss: 0.0821 - val_acc: 0.9721 - val_auc: 0.9966 - val_f1sc: 0.9726 - val_fp: 208.0000 - val_fn: 34.0000 - val_tp: 4302.0000 - val_tn: 4128.0000\n",
      "Epoch 9/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9765Epoch 00008: val_loss did not improve\n",
      "400/400 [==============================] - 326s - loss: 0.0669 - acc: 0.9765 - val_loss: 0.0964 - val_acc: 0.9619 - val_auc: 0.9972 - val_f1sc: 0.9609 - val_fp: 46.0000 - val_fn: 284.0000 - val_tp: 4052.0000 - val_tn: 4290.0000\n",
      "Epoch 10/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9774Epoch 00009: val_loss did not improve\n",
      "400/400 [==============================] - 315s - loss: 0.0648 - acc: 0.9774 - val_loss: 0.0787 - val_acc: 0.9746 - val_auc: 0.9971 - val_f1sc: 0.9743 - val_fp: 53.0000 - val_fn: 167.0000 - val_tp: 4169.0000 - val_tn: 4283.0000\n",
      "Epoch 11/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9771Epoch 00010: val_loss improved from 0.06253 to 0.05868, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 320s - loss: 0.0662 - acc: 0.9771 - val_loss: 0.0587 - val_acc: 0.9789 - val_auc: 0.9977 - val_f1sc: 0.9792 - val_fp: 145.0000 - val_fn: 38.0000 - val_tp: 4298.0000 - val_tn: 4191.0000\n",
      "Epoch 12/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9764Epoch 00011: val_loss improved from 0.05868 to 0.05128, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 317s - loss: 0.0644 - acc: 0.9764 - val_loss: 0.0513 - val_acc: 0.9822 - val_auc: 0.9983 - val_f1sc: 0.9822 - val_fp: 72.0000 - val_fn: 82.0000 - val_tp: 4254.0000 - val_tn: 4264.0000\n",
      "Epoch 13/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9784Epoch 00012: val_loss did not improve\n",
      "400/400 [==============================] - 325s - loss: 0.0609 - acc: 0.9784 - val_loss: 0.0704 - val_acc: 0.9773 - val_auc: 0.9964 - val_f1sc: 0.9776 - val_fp: 154.0000 - val_fn: 43.0000 - val_tp: 4293.0000 - val_tn: 4182.0000\n",
      "Epoch 14/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9763Epoch 00013: val_loss did not improve\n",
      "400/400 [==============================] - 331s - loss: 0.0641 - acc: 0.9764 - val_loss: 0.1027 - val_acc: 0.9649 - val_auc: 0.9966 - val_f1sc: 0.9641 - val_fp: 49.0000 - val_fn: 255.0000 - val_tp: 4081.0000 - val_tn: 4287.0000\n",
      "Epoch 15/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9794Epoch 00014: val_loss did not improve\n",
      "400/400 [==============================] - 301s - loss: 0.0591 - acc: 0.9794 - val_loss: 0.0534 - val_acc: 0.9799 - val_auc: 0.9980 - val_f1sc: 0.9800 - val_fp: 107.0000 - val_fn: 67.0000 - val_tp: 4269.0000 - val_tn: 4229.0000\n",
      "Epoch 16/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9782Epoch 00015: val_loss did not improve\n",
      "400/400 [==============================] - 297s - loss: 0.0609 - acc: 0.9782 - val_loss: 0.0738 - val_acc: 0.9756 - val_auc: 0.9967 - val_f1sc: 0.9759 - val_fp: 168.0000 - val_fn: 44.0000 - val_tp: 4292.0000 - val_tn: 4168.0000\n",
      "Epoch 17/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9785Epoch 00016: val_loss did not improve\n",
      "400/400 [==============================] - 306s - loss: 0.0591 - acc: 0.9784 - val_loss: 0.0675 - val_acc: 0.9768 - val_auc: 0.9975 - val_f1sc: 0.9772 - val_fp: 169.0000 - val_fn: 32.0000 - val_tp: 4304.0000 - val_tn: 4167.0000\n",
      "Epoch 18/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9793Epoch 00017: val_loss improved from 0.05128 to 0.04922, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 313s - loss: 0.0592 - acc: 0.9793 - val_loss: 0.0492 - val_acc: 0.9810 - val_auc: 0.9985 - val_f1sc: 0.9812 - val_fp: 131.0000 - val_fn: 34.0000 - val_tp: 4302.0000 - val_tn: 4205.0000\n",
      "Epoch 19/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9799Epoch 00018: val_loss did not improve\n",
      "400/400 [==============================] - 312s - loss: 0.0571 - acc: 0.9799 - val_loss: 0.0501 - val_acc: 0.9830 - val_auc: 0.9982 - val_f1sc: 0.9832 - val_fp: 102.0000 - val_fn: 45.0000 - val_tp: 4291.0000 - val_tn: 4234.0000\n",
      "Epoch 20/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9799Epoch 00019: val_loss did not improve\n",
      "400/400 [==============================] - 316s - loss: 0.0568 - acc: 0.9800 - val_loss: 0.0497 - val_acc: 0.9833 - val_auc: 0.9982 - val_f1sc: 0.9834 - val_fp: 105.0000 - val_fn: 40.0000 - val_tp: 4296.0000 - val_tn: 4231.0000\n",
      "Epoch 21/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9814Epoch 00020: val_loss improved from 0.04922 to 0.04636, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 310s - loss: 0.0517 - acc: 0.9814 - val_loss: 0.0464 - val_acc: 0.9827 - val_auc: 0.9986 - val_f1sc: 0.9827 - val_fp: 63.0000 - val_fn: 87.0000 - val_tp: 4249.0000 - val_tn: 4273.0000\n",
      "Epoch 22/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9809Epoch 00021: val_loss did not improve\n",
      "400/400 [==============================] - 307s - loss: 0.0550 - acc: 0.9809 - val_loss: 0.0506 - val_acc: 0.9841 - val_auc: 0.9987 - val_f1sc: 0.9843 - val_fp: 120.0000 - val_fn: 18.0000 - val_tp: 4318.0000 - val_tn: 4216.0000\n",
      "Epoch 23/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9810Epoch 00022: val_loss did not improve\n",
      "400/400 [==============================] - 314s - loss: 0.0534 - acc: 0.9810 - val_loss: 0.1114 - val_acc: 0.9594 - val_auc: 0.9959 - val_f1sc: 0.9583 - val_fp: 57.0000 - val_fn: 295.0000 - val_tp: 4041.0000 - val_tn: 4279.0000\n",
      "Epoch 24/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9801Epoch 00023: val_loss did not improve\n",
      "400/400 [==============================] - 314s - loss: 0.0548 - acc: 0.9802 - val_loss: 0.0570 - val_acc: 0.9798 - val_auc: 0.9976 - val_f1sc: 0.9799 - val_fp: 113.0000 - val_fn: 62.0000 - val_tp: 4274.0000 - val_tn: 4223.0000\n",
      "Epoch 25/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9816Epoch 00024: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0499 - acc: 0.9816 - val_loss: 0.0544 - val_acc: 0.9802 - val_auc: 0.9977 - val_f1sc: 0.9802 - val_fp: 93.0000 - val_fn: 79.0000 - val_tp: 4257.0000 - val_tn: 4243.0000\n",
      "Epoch 26/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9798Epoch 00025: val_loss did not improve\n",
      "400/400 [==============================] - 309s - loss: 0.0547 - acc: 0.9798 - val_loss: 0.0525 - val_acc: 0.9814 - val_auc: 0.9983 - val_f1sc: 0.9814 - val_fp: 64.0000 - val_fn: 97.0000 - val_tp: 4239.0000 - val_tn: 4272.0000\n",
      "Epoch 27/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9812Epoch 00026: val_loss did not improve\n",
      "400/400 [==============================] - 310s - loss: 0.0524 - acc: 0.9812 - val_loss: 0.0637 - val_acc: 0.9773 - val_auc: 0.9970 - val_f1sc: 0.9772 - val_fp: 89.0000 - val_fn: 108.0000 - val_tp: 4228.0000 - val_tn: 4247.0000\n",
      "Epoch 28/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9805Epoch 00027: val_loss did not improve\n",
      "400/400 [==============================] - 312s - loss: 0.0558 - acc: 0.9805 - val_loss: 0.0636 - val_acc: 0.9782 - val_auc: 0.9971 - val_f1sc: 0.9783 - val_fp: 106.0000 - val_fn: 83.0000 - val_tp: 4253.0000 - val_tn: 4230.0000\n",
      "Epoch 29/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9845Epoch 00028: val_loss improved from 0.04636 to 0.03654, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 311s - loss: 0.0437 - acc: 0.9845 - val_loss: 0.0365 - val_acc: 0.9869 - val_auc: 0.9991 - val_f1sc: 0.9869 - val_fp: 68.0000 - val_fn: 46.0000 - val_tp: 4290.0000 - val_tn: 4268.0000\n",
      "Epoch 30/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9839Epoch 00029: val_loss did not improve\n",
      "400/400 [==============================] - 315s - loss: 0.0451 - acc: 0.9839 - val_loss: 0.0381 - val_acc: 0.9870 - val_auc: 0.9990 - val_f1sc: 0.9871 - val_fp: 84.0000 - val_fn: 29.0000 - val_tp: 4307.0000 - val_tn: 4252.0000\n",
      "Epoch 31/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9854Epoch 00030: val_loss did not improve\n",
      "400/400 [==============================] - 313s - loss: 0.0415 - acc: 0.9854 - val_loss: 0.0457 - val_acc: 0.9851 - val_auc: 0.9987 - val_f1sc: 0.9851 - val_fp: 51.0000 - val_fn: 78.0000 - val_tp: 4258.0000 - val_tn: 4285.0000\n",
      "Epoch 32/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9854Epoch 00031: val_loss did not improve\n",
      "400/400 [==============================] - 316s - loss: 0.0413 - acc: 0.9854 - val_loss: 0.0374 - val_acc: 0.9862 - val_auc: 0.9991 - val_f1sc: 0.9862 - val_fp: 70.0000 - val_fn: 50.0000 - val_tp: 4286.0000 - val_tn: 4266.0000\n",
      "Epoch 33/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9859Epoch 00032: val_loss did not improve\n",
      "400/400 [==============================] - 318s - loss: 0.0395 - acc: 0.9859 - val_loss: 0.0413 - val_acc: 0.9865 - val_auc: 0.9988 - val_f1sc: 0.9866 - val_fp: 77.0000 - val_fn: 40.0000 - val_tp: 4296.0000 - val_tn: 4259.0000\n",
      "Epoch 34/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9862Epoch 00033: val_loss did not improve\n",
      "400/400 [==============================] - 308s - loss: 0.0402 - acc: 0.9862 - val_loss: 0.0382 - val_acc: 0.9859 - val_auc: 0.9990 - val_f1sc: 0.9860 - val_fp: 76.0000 - val_fn: 46.0000 - val_tp: 4290.0000 - val_tn: 4260.0000\n",
      "Epoch 35/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9866Epoch 00034: val_loss did not improve\n",
      "400/400 [==============================] - 308s - loss: 0.0387 - acc: 0.9867 - val_loss: 0.0365 - val_acc: 0.9881 - val_auc: 0.9989 - val_f1sc: 0.9881 - val_fp: 60.0000 - val_fn: 43.0000 - val_tp: 4293.0000 - val_tn: 4276.0000\n",
      "Epoch 36/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9852Epoch 00035: val_loss improved from 0.03654 to 0.03563, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 311s - loss: 0.0388 - acc: 0.9852 - val_loss: 0.0356 - val_acc: 0.9871 - val_auc: 0.9992 - val_f1sc: 0.9872 - val_fp: 78.0000 - val_fn: 34.0000 - val_tp: 4302.0000 - val_tn: 4258.0000\n",
      "Epoch 37/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9849Epoch 00036: val_loss did not improve\n",
      "400/400 [==============================] - 313s - loss: 0.0389 - acc: 0.9850 - val_loss: 0.0453 - val_acc: 0.9845 - val_auc: 0.9986 - val_f1sc: 0.9846 - val_fp: 68.0000 - val_fn: 66.0000 - val_tp: 4270.0000 - val_tn: 4268.0000\n",
      "Epoch 38/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9866Epoch 00037: val_loss improved from 0.03563 to 0.03284, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 316s - loss: 0.0391 - acc: 0.9865 - val_loss: 0.0328 - val_acc: 0.9887 - val_auc: 0.9992 - val_f1sc: 0.9887 - val_fp: 55.0000 - val_fn: 43.0000 - val_tp: 4293.0000 - val_tn: 4281.0000\n",
      "Epoch 39/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9862Epoch 00038: val_loss did not improve\n",
      "400/400 [==============================] - 312s - loss: 0.0392 - acc: 0.9862 - val_loss: 0.0353 - val_acc: 0.9873 - val_auc: 0.9991 - val_f1sc: 0.9874 - val_fp: 74.0000 - val_fn: 36.0000 - val_tp: 4300.0000 - val_tn: 4262.0000\n",
      "Epoch 40/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9847Epoch 00039: val_loss did not improve\n",
      "400/400 [==============================] - 310s - loss: 0.0388 - acc: 0.9848 - val_loss: 0.0435 - val_acc: 0.9858 - val_auc: 0.9985 - val_f1sc: 0.9858 - val_fp: 71.0000 - val_fn: 52.0000 - val_tp: 4284.0000 - val_tn: 4265.0000\n",
      "Epoch 41/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9870Epoch 00040: val_loss did not improve\n",
      "400/400 [==============================] - 313s - loss: 0.0361 - acc: 0.9870 - val_loss: 0.0359 - val_acc: 0.9866 - val_auc: 0.9992 - val_f1sc: 0.9866 - val_fp: 51.0000 - val_fn: 65.0000 - val_tp: 4271.0000 - val_tn: 4285.0000\n",
      "Epoch 42/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9857Epoch 00041: val_loss did not improve\n",
      "400/400 [==============================] - 325s - loss: 0.0410 - acc: 0.9857 - val_loss: 0.0368 - val_acc: 0.9877 - val_auc: 0.9988 - val_f1sc: 0.9877 - val_fp: 68.0000 - val_fn: 39.0000 - val_tp: 4297.0000 - val_tn: 4268.0000\n",
      "Epoch 43/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9873Epoch 00042: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 332s - loss: 0.0350 - acc: 0.9873 - val_loss: 0.0421 - val_acc: 0.9871 - val_auc: 0.9987 - val_f1sc: 0.9871 - val_fp: 66.0000 - val_fn: 46.0000 - val_tp: 4290.0000 - val_tn: 4270.0000\n",
      "Epoch 44/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9853Epoch 00043: val_loss did not improve\n",
      "400/400 [==============================] - 332s - loss: 0.0402 - acc: 0.9852 - val_loss: 0.0467 - val_acc: 0.9843 - val_auc: 0.9989 - val_f1sc: 0.9842 - val_fp: 43.0000 - val_fn: 93.0000 - val_tp: 4243.0000 - val_tn: 4293.0000\n",
      "Epoch 45/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9877Epoch 00044: val_loss did not improve\n",
      "400/400 [==============================] - 331s - loss: 0.0360 - acc: 0.9877 - val_loss: 0.0358 - val_acc: 0.9874 - val_auc: 0.9989 - val_f1sc: 0.9875 - val_fp: 76.0000 - val_fn: 33.0000 - val_tp: 4303.0000 - val_tn: 4260.0000\n",
      "Epoch 46/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9876Epoch 00045: val_loss improved from 0.03284 to 0.02950, saving model to model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "400/400 [==============================] - 329s - loss: 0.0357 - acc: 0.9876 - val_loss: 0.0295 - val_acc: 0.9892 - val_auc: 0.9993 - val_f1sc: 0.9892 - val_fp: 69.0000 - val_fn: 25.0000 - val_tp: 4311.0000 - val_tn: 4267.0000\n",
      "Epoch 47/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9894Epoch 00046: val_loss did not improve\n",
      "400/400 [==============================] - 329s - loss: 0.0301 - acc: 0.9894 - val_loss: 0.0324 - val_acc: 0.9885 - val_auc: 0.9993 - val_f1sc: 0.9885 - val_fp: 53.0000 - val_fn: 47.0000 - val_tp: 4289.0000 - val_tn: 4283.0000\n",
      "Epoch 48/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9890Epoch 00047: val_loss did not improve\n",
      "400/400 [==============================] - 330s - loss: 0.0300 - acc: 0.9890 - val_loss: 0.0369 - val_acc: 0.9869 - val_auc: 0.9991 - val_f1sc: 0.9868 - val_fp: 54.0000 - val_fn: 60.0000 - val_tp: 4276.0000 - val_tn: 4282.0000\n",
      "Epoch 49/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9880Epoch 00048: val_loss did not improve\n",
      "400/400 [==============================] - 331s - loss: 0.0331 - acc: 0.9880 - val_loss: 0.0325 - val_acc: 0.9875 - val_auc: 0.9992 - val_f1sc: 0.9876 - val_fp: 62.0000 - val_fn: 46.0000 - val_tp: 4290.0000 - val_tn: 4274.0000\n",
      "Epoch 50/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9886Epoch 00049: val_loss did not improve\n",
      "400/400 [==============================] - 328s - loss: 0.0316 - acc: 0.9886 - val_loss: 0.0363 - val_acc: 0.9872 - val_auc: 0.9992 - val_f1sc: 0.9872 - val_fp: 59.0000 - val_fn: 52.0000 - val_tp: 4284.0000 - val_tn: 4277.0000\n",
      "Epoch 51/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9894Epoch 00050: val_loss did not improve\n",
      "400/400 [==============================] - 329s - loss: 0.0299 - acc: 0.9893 - val_loss: 0.0345 - val_acc: 0.9885 - val_auc: 0.9990 - val_f1sc: 0.9885 - val_fp: 54.0000 - val_fn: 46.0000 - val_tp: 4290.0000 - val_tn: 4282.0000\n",
      "Epoch 52/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9913Epoch 00051: val_loss did not improve\n",
      "400/400 [==============================] - 330s - loss: 0.0268 - acc: 0.9913 - val_loss: 0.0311 - val_acc: 0.9897 - val_auc: 0.9992 - val_f1sc: 0.9897 - val_fp: 49.0000 - val_fn: 40.0000 - val_tp: 4296.0000 - val_tn: 4287.0000\n",
      "Epoch 53/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9886Epoch 00052: val_loss did not improve\n",
      "400/400 [==============================] - 332s - loss: 0.0301 - acc: 0.9886 - val_loss: 0.0326 - val_acc: 0.9900 - val_auc: 0.9993 - val_f1sc: 0.9900 - val_fp: 41.0000 - val_fn: 46.0000 - val_tp: 4290.0000 - val_tn: 4295.0000\n",
      "Epoch 54/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9895Epoch 00053: val_loss did not improve\n",
      "400/400 [==============================] - 332s - loss: 0.0281 - acc: 0.9895 - val_loss: 0.0326 - val_acc: 0.9886 - val_auc: 0.9993 - val_f1sc: 0.9886 - val_fp: 58.0000 - val_fn: 41.0000 - val_tp: 4295.0000 - val_tn: 4278.0000\n",
      "Epoch 55/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9903Epoch 00054: val_loss did not improve\n",
      "400/400 [==============================] - 329s - loss: 0.0266 - acc: 0.9903 - val_loss: 0.0312 - val_acc: 0.9903 - val_auc: 0.9994 - val_f1sc: 0.9903 - val_fp: 38.0000 - val_fn: 46.0000 - val_tp: 4290.0000 - val_tn: 4298.0000\n",
      "Epoch 56/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9899Epoch 00055: val_loss did not improve\n",
      "400/400 [==============================] - 329s - loss: 0.0285 - acc: 0.9899 - val_loss: 0.0375 - val_acc: 0.9877 - val_auc: 0.9992 - val_f1sc: 0.9876 - val_fp: 44.0000 - val_fn: 63.0000 - val_tp: 4273.0000 - val_tn: 4292.0000\n",
      "Epoch 57/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9898Epoch 00056: val_loss did not improve\n",
      "400/400 [==============================] - 330s - loss: 0.0285 - acc: 0.9898 - val_loss: 0.0309 - val_acc: 0.9899 - val_auc: 0.9992 - val_f1sc: 0.9899 - val_fp: 59.0000 - val_fn: 29.0000 - val_tp: 4307.0000 - val_tn: 4277.0000\n",
      "Epoch 58/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9897Epoch 00057: val_loss did not improve\n",
      "400/400 [==============================] - 329s - loss: 0.0289 - acc: 0.9897 - val_loss: 0.0325 - val_acc: 0.9895 - val_auc: 0.9991 - val_f1sc: 0.9895 - val_fp: 54.0000 - val_fn: 37.0000 - val_tp: 4299.0000 - val_tn: 4282.0000\n",
      "Epoch 59/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9910Epoch 00058: val_loss did not improve\n",
      "400/400 [==============================] - 331s - loss: 0.0257 - acc: 0.9910 - val_loss: 0.0327 - val_acc: 0.9900 - val_auc: 0.9992 - val_f1sc: 0.9900 - val_fp: 46.0000 - val_fn: 41.0000 - val_tp: 4295.0000 - val_tn: 4290.0000\n",
      "Epoch 60/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9901Epoch 00059: val_loss did not improve\n",
      "400/400 [==============================] - 331s - loss: 0.0285 - acc: 0.9901 - val_loss: 0.0337 - val_acc: 0.9889 - val_auc: 0.9992 - val_f1sc: 0.9889 - val_fp: 48.0000 - val_fn: 48.0000 - val_tp: 4288.0000 - val_tn: 4288.0000\n",
      "Epoch 61/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9916Epoch 00060: val_loss did not improve\n",
      "400/400 [==============================] - 330s - loss: 0.0253 - acc: 0.9916 - val_loss: 0.0322 - val_acc: 0.9896 - val_auc: 0.9992 - val_f1sc: 0.9896 - val_fp: 53.0000 - val_fn: 37.0000 - val_tp: 4299.0000 - val_tn: 4283.0000\n",
      "Epoch 62/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9915Epoch 00061: val_loss did not improve\n",
      "400/400 [==============================] - 329s - loss: 0.0246 - acc: 0.9914 - val_loss: 0.0326 - val_acc: 0.9897 - val_auc: 0.9992 - val_f1sc: 0.9897 - val_fp: 44.0000 - val_fn: 45.0000 - val_tp: 4291.0000 - val_tn: 4292.0000\n",
      "6.21448\n",
      "runung index: 0\n",
      "39.17853236198425\n",
      "runung index: 1\n",
      "37.29506039619446\n",
      "runung index: 2\n",
      "37.4403190612793\n",
      "runung index: 3\n",
      "37.37554216384888\n",
      "runung index: 4\n",
      "37.380677938461304\n",
      "runung index: 5\n",
      "37.44952845573425\n",
      "runung index: 6\n",
      "8.060314178466797\n",
      "doing training set prediction\n",
      "15.0656\n",
      "runung index: 0\n",
      "40.149373292922974\n",
      "runung index: 1\n",
      "37.41170120239258\n",
      "runung index: 2\n",
      "37.33612775802612\n",
      "runung index: 3\n",
      "37.209747076034546\n",
      "runung index: 4\n",
      "37.07895374298096\n",
      "runung index: 5\n",
      "37.26848363876343\n",
      "runung index: 6\n",
      "37.31501531600952\n",
      "runung index: 7\n",
      "37.20440649986267\n",
      "runung index: 8\n",
      "37.22254252433777\n",
      "runung index: 9\n",
      "37.12575626373291\n",
      "runung index: 10\n",
      "37.33307886123657\n",
      "runung index: 11\n",
      "37.321831941604614\n",
      "runung index: 12\n",
      "37.19296598434448\n",
      "runung index: 13\n",
      "37.25576615333557\n",
      "runung index: 14\n",
      "37.211602449417114\n",
      "runung index: 15\n",
      "2.4573771953582764\n",
      "Next generation nonC size: (216210, 3)\n",
      "We are now at generation2\n",
      "loading exist model: model/model_hard_negative_thresh10_gen1_k3.h5\n",
      "Epoch 1/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9851Epoch 00000: val_loss improved from inf to 0.04281, saving model to model/model_hard_negative_thresh10_gen2_k3.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 429s - loss: 0.0419 - acc: 0.9850 - val_loss: 0.0428 - val_acc: 0.9852 - val_auc: 0.9987 - val_f1sc: 0.9853 - val_fp: 91.0000 - val_fn: 37.0000 - val_tp: 4299.0000 - val_tn: 4245.0000\n",
      "Epoch 2/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9823Epoch 00001: val_loss did not improve\n",
      "400/400 [==============================] - 330s - loss: 0.0499 - acc: 0.9823 - val_loss: 0.0445 - val_acc: 0.9847 - val_auc: 0.9987 - val_f1sc: 0.9847 - val_fp: 76.0000 - val_fn: 57.0000 - val_tp: 4279.0000 - val_tn: 4260.0000\n",
      "Epoch 3/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9832Epoch 00002: val_loss did not improve\n",
      "400/400 [==============================] - 330s - loss: 0.0473 - acc: 0.9832 - val_loss: 0.0482 - val_acc: 0.9829 - val_auc: 0.9986 - val_f1sc: 0.9831 - val_fp: 121.0000 - val_fn: 27.0000 - val_tp: 4309.0000 - val_tn: 4215.0000\n",
      "Epoch 4/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9841Epoch 00003: val_loss did not improve\n",
      "400/400 [==============================] - 329s - loss: 0.0440 - acc: 0.9841 - val_loss: 0.0660 - val_acc: 0.9749 - val_auc: 0.9982 - val_f1sc: 0.9745 - val_fp: 54.0000 - val_fn: 164.0000 - val_tp: 4172.0000 - val_tn: 4282.0000\n",
      "Epoch 5/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9841Epoch 00004: val_loss did not improve\n",
      "400/400 [==============================] - 330s - loss: 0.0446 - acc: 0.9841 - val_loss: 0.0539 - val_acc: 0.9826 - val_auc: 0.9984 - val_f1sc: 0.9825 - val_fp: 64.0000 - val_fn: 87.0000 - val_tp: 4249.0000 - val_tn: 4272.0000\n",
      "Epoch 6/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9839Epoch 00005: val_loss did not improve\n",
      "400/400 [==============================] - 330s - loss: 0.0456 - acc: 0.9840 - val_loss: 0.0927 - val_acc: 0.9684 - val_auc: 0.9965 - val_f1sc: 0.9678 - val_fp: 53.0000 - val_fn: 221.0000 - val_tp: 4115.0000 - val_tn: 4283.0000\n",
      "Epoch 7/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9842Epoch 00006: val_loss did not improve\n",
      "400/400 [==============================] - 328s - loss: 0.0442 - acc: 0.9842 - val_loss: 0.0490 - val_acc: 0.9829 - val_auc: 0.9984 - val_f1sc: 0.9831 - val_fp: 113.0000 - val_fn: 35.0000 - val_tp: 4301.0000 - val_tn: 4223.0000\n",
      "Epoch 8/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9844Epoch 00007: val_loss improved from 0.04281 to 0.03950, saving model to model/model_hard_negative_thresh10_gen2_k3.h5\n",
      "400/400 [==============================] - 330s - loss: 0.0453 - acc: 0.9843 - val_loss: 0.0395 - val_acc: 0.9851 - val_auc: 0.9990 - val_f1sc: 0.9852 - val_fp: 88.0000 - val_fn: 41.0000 - val_tp: 4295.0000 - val_tn: 4248.0000\n",
      "Epoch 9/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9849Epoch 00008: val_loss did not improve\n",
      "400/400 [==============================] - 329s - loss: 0.0441 - acc: 0.9849 - val_loss: 0.0470 - val_acc: 0.9821 - val_auc: 0.9986 - val_f1sc: 0.9820 - val_fp: 55.0000 - val_fn: 100.0000 - val_tp: 4236.0000 - val_tn: 4281.0000\n",
      "Epoch 10/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9848Epoch 00009: val_loss did not improve\n",
      "400/400 [==============================] - 329s - loss: 0.0434 - acc: 0.9848 - val_loss: 0.0528 - val_acc: 0.9804 - val_auc: 0.9981 - val_f1sc: 0.9805 - val_fp: 114.0000 - val_fn: 56.0000 - val_tp: 4280.0000 - val_tn: 4222.0000\n",
      "Epoch 11/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9838Epoch 00010: val_loss did not improve\n",
      "400/400 [==============================] - 328s - loss: 0.0447 - acc: 0.9838 - val_loss: 0.0598 - val_acc: 0.9821 - val_auc: 0.9970 - val_f1sc: 0.9822 - val_fp: 96.0000 - val_fn: 59.0000 - val_tp: 4277.0000 - val_tn: 4240.0000\n",
      "Epoch 12/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9836Epoch 00011: val_loss did not improve\n",
      "400/400 [==============================] - 330s - loss: 0.0437 - acc: 0.9836 - val_loss: 0.0423 - val_acc: 0.9854 - val_auc: 0.9989 - val_f1sc: 0.9853 - val_fp: 55.0000 - val_fn: 72.0000 - val_tp: 4264.0000 - val_tn: 4281.0000\n",
      "Epoch 13/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9846Epoch 00012: val_loss did not improve\n",
      "400/400 [==============================] - 330s - loss: 0.0420 - acc: 0.9847 - val_loss: 0.0780 - val_acc: 0.9756 - val_auc: 0.9967 - val_f1sc: 0.9754 - val_fp: 76.0000 - val_fn: 136.0000 - val_tp: 4200.0000 - val_tn: 4260.0000\n",
      "Epoch 14/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9834Epoch 00013: val_loss did not improve\n",
      "400/400 [==============================] - 329s - loss: 0.0471 - acc: 0.9834 - val_loss: 0.0501 - val_acc: 0.9840 - val_auc: 0.9981 - val_f1sc: 0.9839 - val_fp: 60.0000 - val_fn: 79.0000 - val_tp: 4257.0000 - val_tn: 4276.0000\n",
      "Epoch 15/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9700Epoch 00014: val_loss did not improve\n",
      "400/400 [==============================] - 334s - loss: 0.0728 - acc: 0.9700 - val_loss: 0.0567 - val_acc: 0.9818 - val_auc: 0.9983 - val_f1sc: 0.9816 - val_fp: 37.0000 - val_fn: 121.0000 - val_tp: 4215.0000 - val_tn: 4299.0000\n",
      "Epoch 16/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9748Epoch 00015: val_loss did not improve\n",
      "400/400 [==============================] - 333s - loss: 0.0605 - acc: 0.9748 - val_loss: 0.0457 - val_acc: 0.9847 - val_auc: 0.9992 - val_f1sc: 0.9845 - val_fp: 23.0000 - val_fn: 110.0000 - val_tp: 4226.0000 - val_tn: 4313.0000\n",
      "Epoch 17/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9773Epoch 00016: val_loss improved from 0.03950 to 0.03368, saving model to model/model_hard_negative_thresh10_gen2_k3.h5\n",
      "400/400 [==============================] - 332s - loss: 0.0561 - acc: 0.9773 - val_loss: 0.0337 - val_acc: 0.9884 - val_auc: 0.9993 - val_f1sc: 0.9883 - val_fp: 46.0000 - val_fn: 55.0000 - val_tp: 4281.0000 - val_tn: 4290.0000\n",
      "Epoch 18/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9885Epoch 00017: val_loss did not improve\n",
      "400/400 [==============================] - 331s - loss: 0.0313 - acc: 0.9886 - val_loss: 0.0345 - val_acc: 0.9875 - val_auc: 0.9992 - val_f1sc: 0.9876 - val_fp: 59.0000 - val_fn: 49.0000 - val_tp: 4287.0000 - val_tn: 4277.0000\n",
      "Epoch 19/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9867Epoch 00018: val_loss did not improve\n",
      "400/400 [==============================] - 321s - loss: 0.0357 - acc: 0.9867 - val_loss: 0.0395 - val_acc: 0.9856 - val_auc: 0.9990 - val_f1sc: 0.9855 - val_fp: 44.0000 - val_fn: 81.0000 - val_tp: 4255.0000 - val_tn: 4292.0000\n",
      "Epoch 20/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9888Epoch 00019: val_loss did not improve\n",
      "400/400 [==============================] - 320s - loss: 0.0323 - acc: 0.9887 - val_loss: 0.0345 - val_acc: 0.9870 - val_auc: 0.9992 - val_f1sc: 0.9871 - val_fp: 86.0000 - val_fn: 27.0000 - val_tp: 4309.0000 - val_tn: 4250.0000\n",
      "Epoch 21/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9883Epoch 00020: val_loss did not improve\n",
      "400/400 [==============================] - 314s - loss: 0.0341 - acc: 0.9883 - val_loss: 0.0390 - val_acc: 0.9863 - val_auc: 0.9991 - val_f1sc: 0.9862 - val_fp: 49.0000 - val_fn: 70.0000 - val_tp: 4266.0000 - val_tn: 4287.0000\n",
      "Epoch 22/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9898Epoch 00021: val_loss did not improve\n",
      "400/400 [==============================] - 316s - loss: 0.0288 - acc: 0.9898 - val_loss: 0.0461 - val_acc: 0.9849 - val_auc: 0.9985 - val_f1sc: 0.9849 - val_fp: 71.0000 - val_fn: 60.0000 - val_tp: 4276.0000 - val_tn: 4265.0000\n",
      "Epoch 23/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9891Epoch 00022: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 315s - loss: 0.0314 - acc: 0.9891 - val_loss: 0.0362 - val_acc: 0.9872 - val_auc: 0.9991 - val_f1sc: 0.9872 - val_fp: 69.0000 - val_fn: 42.0000 - val_tp: 4294.0000 - val_tn: 4267.0000\n",
      "Epoch 24/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9884Epoch 00023: val_loss did not improve\n",
      "400/400 [==============================] - 313s - loss: 0.0328 - acc: 0.9884 - val_loss: 0.0400 - val_acc: 0.9849 - val_auc: 0.9990 - val_f1sc: 0.9849 - val_fp: 77.0000 - val_fn: 54.0000 - val_tp: 4282.0000 - val_tn: 4259.0000\n",
      "Epoch 25/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9893Epoch 00024: val_loss did not improve\n",
      "400/400 [==============================] - 318s - loss: 0.0300 - acc: 0.9892 - val_loss: 0.0353 - val_acc: 0.9880 - val_auc: 0.9992 - val_f1sc: 0.9880 - val_fp: 51.0000 - val_fn: 53.0000 - val_tp: 4283.0000 - val_tn: 4285.0000\n",
      "Epoch 26/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9902Epoch 00025: val_loss did not improve\n",
      "400/400 [==============================] - 319s - loss: 0.0275 - acc: 0.9902 - val_loss: 0.0357 - val_acc: 0.9877 - val_auc: 0.9991 - val_f1sc: 0.9877 - val_fp: 50.0000 - val_fn: 57.0000 - val_tp: 4279.0000 - val_tn: 4286.0000\n",
      "Epoch 27/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9904Epoch 00026: val_loss did not improve\n",
      "400/400 [==============================] - 314s - loss: 0.0283 - acc: 0.9904 - val_loss: 0.0346 - val_acc: 0.9874 - val_auc: 0.9991 - val_f1sc: 0.9874 - val_fp: 53.0000 - val_fn: 56.0000 - val_tp: 4280.0000 - val_tn: 4283.0000\n",
      "Epoch 28/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9902Epoch 00027: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0280 - acc: 0.9902 - val_loss: 0.0385 - val_acc: 0.9875 - val_auc: 0.9991 - val_f1sc: 0.9875 - val_fp: 52.0000 - val_fn: 56.0000 - val_tp: 4280.0000 - val_tn: 4284.0000\n",
      "Epoch 29/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9892Epoch 00028: val_loss did not improve\n",
      "400/400 [==============================] - 312s - loss: 0.0289 - acc: 0.9892 - val_loss: 0.0391 - val_acc: 0.9860 - val_auc: 0.9992 - val_f1sc: 0.9860 - val_fp: 60.0000 - val_fn: 61.0000 - val_tp: 4275.0000 - val_tn: 4276.0000\n",
      "Epoch 30/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9911Epoch 00029: val_loss improved from 0.03368 to 0.02994, saving model to model/model_hard_negative_thresh10_gen2_k3.h5\n",
      "400/400 [==============================] - 316s - loss: 0.0252 - acc: 0.9911 - val_loss: 0.0299 - val_acc: 0.9896 - val_auc: 0.9994 - val_f1sc: 0.9896 - val_fp: 48.0000 - val_fn: 42.0000 - val_tp: 4294.0000 - val_tn: 4288.0000\n",
      "Epoch 31/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9881Epoch 00030: val_loss did not improve\n",
      "400/400 [==============================] - 315s - loss: 0.0346 - acc: 0.9880 - val_loss: 0.0437 - val_acc: 0.9849 - val_auc: 0.9993 - val_f1sc: 0.9848 - val_fp: 28.0000 - val_fn: 103.0000 - val_tp: 4233.0000 - val_tn: 4308.0000\n",
      "Epoch 32/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9791Epoch 00031: val_loss did not improve\n",
      "400/400 [==============================] - 315s - loss: 0.0493 - acc: 0.9792 - val_loss: 0.0366 - val_acc: 0.9890 - val_auc: 0.9991 - val_f1sc: 0.9890 - val_fp: 31.0000 - val_fn: 64.0000 - val_tp: 4272.0000 - val_tn: 4305.0000\n",
      "Epoch 33/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9821Epoch 00032: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0452 - acc: 0.9821 - val_loss: 0.0429 - val_acc: 0.9855 - val_auc: 0.9992 - val_f1sc: 0.9853 - val_fp: 19.0000 - val_fn: 107.0000 - val_tp: 4229.0000 - val_tn: 4317.0000\n",
      "Epoch 34/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9839Epoch 00033: val_loss did not improve\n",
      "400/400 [==============================] - 314s - loss: 0.0423 - acc: 0.9839 - val_loss: 0.0404 - val_acc: 0.9867 - val_auc: 0.9992 - val_f1sc: 0.9867 - val_fp: 39.0000 - val_fn: 76.0000 - val_tp: 4260.0000 - val_tn: 4297.0000\n",
      "Epoch 35/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9911Epoch 00034: val_loss did not improve\n",
      "400/400 [==============================] - 316s - loss: 0.0251 - acc: 0.9911 - val_loss: 0.0360 - val_acc: 0.9863 - val_auc: 0.9992 - val_f1sc: 0.9863 - val_fp: 58.0000 - val_fn: 61.0000 - val_tp: 4275.0000 - val_tn: 4278.0000\n",
      "Epoch 36/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9910Epoch 00035: val_loss did not improve\n",
      "400/400 [==============================] - 319s - loss: 0.0269 - acc: 0.9910 - val_loss: 0.0348 - val_acc: 0.9869 - val_auc: 0.9993 - val_f1sc: 0.9869 - val_fp: 57.0000 - val_fn: 57.0000 - val_tp: 4279.0000 - val_tn: 4279.0000\n",
      "Epoch 37/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9906Epoch 00036: val_loss did not improve\n",
      "400/400 [==============================] - 316s - loss: 0.0272 - acc: 0.9906 - val_loss: 0.0351 - val_acc: 0.9874 - val_auc: 0.9991 - val_f1sc: 0.9874 - val_fp: 54.0000 - val_fn: 55.0000 - val_tp: 4281.0000 - val_tn: 4282.0000\n",
      "Epoch 38/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9912Epoch 00037: val_loss did not improve\n",
      "400/400 [==============================] - 314s - loss: 0.0261 - acc: 0.9912 - val_loss: 0.0408 - val_acc: 0.9858 - val_auc: 0.9992 - val_f1sc: 0.9858 - val_fp: 42.0000 - val_fn: 81.0000 - val_tp: 4255.0000 - val_tn: 4294.0000\n",
      "Epoch 39/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9919Epoch 00038: val_loss did not improve\n",
      "400/400 [==============================] - 320s - loss: 0.0231 - acc: 0.9919 - val_loss: 0.0378 - val_acc: 0.9882 - val_auc: 0.9992 - val_f1sc: 0.9882 - val_fp: 45.0000 - val_fn: 57.0000 - val_tp: 4279.0000 - val_tn: 4291.0000\n",
      "Epoch 40/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9919Epoch 00039: val_loss did not improve\n",
      "400/400 [==============================] - 316s - loss: 0.0225 - acc: 0.9919 - val_loss: 0.0357 - val_acc: 0.9889 - val_auc: 0.9992 - val_f1sc: 0.9889 - val_fp: 48.0000 - val_fn: 48.0000 - val_tp: 4288.0000 - val_tn: 4288.0000\n",
      "Epoch 41/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9921Epoch 00040: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0226 - acc: 0.9921 - val_loss: 0.0369 - val_acc: 0.9882 - val_auc: 0.9993 - val_f1sc: 0.9882 - val_fp: 43.0000 - val_fn: 59.0000 - val_tp: 4277.0000 - val_tn: 4293.0000\n",
      "Epoch 42/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9913Epoch 00041: val_loss did not improve\n",
      "400/400 [==============================] - 318s - loss: 0.0250 - acc: 0.9913 - val_loss: 0.0342 - val_acc: 0.9880 - val_auc: 0.9993 - val_f1sc: 0.9880 - val_fp: 45.0000 - val_fn: 59.0000 - val_tp: 4277.0000 - val_tn: 4291.0000\n",
      "Epoch 43/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9923Epoch 00042: val_loss did not improve\n",
      "400/400 [==============================] - 320s - loss: 0.0228 - acc: 0.9923 - val_loss: 0.0327 - val_acc: 0.9889 - val_auc: 0.9993 - val_f1sc: 0.9889 - val_fp: 49.0000 - val_fn: 47.0000 - val_tp: 4289.0000 - val_tn: 4287.0000\n",
      "Epoch 44/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9923Epoch 00043: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0228 - acc: 0.9922 - val_loss: 0.0353 - val_acc: 0.9885 - val_auc: 0.9993 - val_f1sc: 0.9884 - val_fp: 39.0000 - val_fn: 61.0000 - val_tp: 4275.0000 - val_tn: 4297.0000\n",
      "Epoch 45/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9922Epoch 00044: val_loss did not improve\n",
      "400/400 [==============================] - 316s - loss: 0.0214 - acc: 0.9922 - val_loss: 0.0341 - val_acc: 0.9890 - val_auc: 0.9992 - val_f1sc: 0.9890 - val_fp: 49.0000 - val_fn: 46.0000 - val_tp: 4290.0000 - val_tn: 4287.0000\n",
      "Epoch 46/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/400 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9919Epoch 00045: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0229 - acc: 0.9919 - val_loss: 0.0356 - val_acc: 0.9882 - val_auc: 0.9992 - val_f1sc: 0.9882 - val_fp: 39.0000 - val_fn: 63.0000 - val_tp: 4273.0000 - val_tn: 4297.0000\n",
      "6.21448\n",
      "runung index: 0\n",
      "39.92813968658447\n",
      "runung index: 1\n",
      "37.04754567146301\n",
      "runung index: 2\n",
      "37.16007161140442\n",
      "runung index: 3\n",
      "37.155561685562134\n",
      "runung index: 4\n",
      "37.06194019317627\n",
      "runung index: 5\n",
      "37.1908655166626\n",
      "runung index: 6\n",
      "8.000077962875366\n",
      "doing training set prediction\n",
      "15.0656\n",
      "runung index: 0\n",
      "40.605916261672974\n",
      "runung index: 1\n",
      "37.33028864860535\n",
      "runung index: 2\n",
      "37.210145473480225\n",
      "runung index: 3\n",
      "37.264198303222656\n",
      "runung index: 4\n",
      "37.355626821517944\n",
      "runung index: 5\n",
      "37.33407187461853\n",
      "runung index: 6\n",
      "37.35201859474182\n",
      "runung index: 7\n",
      "37.343751192092896\n",
      "runung index: 8\n",
      "37.25987195968628\n",
      "runung index: 9\n",
      "37.396915435791016\n",
      "runung index: 10\n",
      "37.33290147781372\n",
      "runung index: 11\n",
      "37.338616132736206\n",
      "runung index: 12\n",
      "37.23989534378052\n",
      "runung index: 13\n",
      "37.34236264228821\n",
      "runung index: 14\n",
      "37.24082827568054\n",
      "runung index: 15\n",
      "2.426393985748291\n",
      "Next generation nonC size: (253090, 3)\n",
      "We are now at generation3\n",
      "loading exist model: model/model_hard_negative_thresh10_gen2_k3.h5\n",
      "Epoch 1/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9879Epoch 00000: val_loss improved from inf to 0.06881, saving model to model/model_hard_negative_thresh10_gen3_k3.h5\n",
      "400/400 [==============================] - 411s - loss: 0.0334 - acc: 0.9879 - val_loss: 0.0688 - val_acc: 0.9801 - val_auc: 0.9985 - val_f1sc: 0.9803 - val_fp: 152.0000 - val_fn: 21.0000 - val_tp: 4315.0000 - val_tn: 4184.0000\n",
      "Epoch 2/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9853Epoch 00001: val_loss improved from 0.06881 to 0.05398, saving model to model/model_hard_negative_thresh10_gen3_k3.h5\n",
      "400/400 [==============================] - 320s - loss: 0.0419 - acc: 0.9853 - val_loss: 0.0540 - val_acc: 0.9807 - val_auc: 0.9988 - val_f1sc: 0.9805 - val_fp: 39.0000 - val_fn: 128.0000 - val_tp: 4208.0000 - val_tn: 4297.0000\n",
      "Epoch 3/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9865Epoch 00002: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0380 - acc: 0.9865 - val_loss: 0.0584 - val_acc: 0.9806 - val_auc: 0.9971 - val_f1sc: 0.9808 - val_fp: 113.0000 - val_fn: 55.0000 - val_tp: 4281.0000 - val_tn: 4223.0000\n",
      "Epoch 4/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9856Epoch 00003: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0393 - acc: 0.9856 - val_loss: 0.0595 - val_acc: 0.9824 - val_auc: 0.9977 - val_f1sc: 0.9823 - val_fp: 58.0000 - val_fn: 95.0000 - val_tp: 4241.0000 - val_tn: 4278.0000\n",
      "Epoch 5/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9857Epoch 00004: val_loss improved from 0.05398 to 0.05178, saving model to model/model_hard_negative_thresh10_gen3_k3.h5\n",
      "400/400 [==============================] - 315s - loss: 0.0411 - acc: 0.9857 - val_loss: 0.0518 - val_acc: 0.9813 - val_auc: 0.9986 - val_f1sc: 0.9812 - val_fp: 60.0000 - val_fn: 102.0000 - val_tp: 4234.0000 - val_tn: 4276.0000\n",
      "Epoch 6/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9859Epoch 00005: val_loss did not improve\n",
      "400/400 [==============================] - 316s - loss: 0.0417 - acc: 0.9859 - val_loss: 0.0598 - val_acc: 0.9789 - val_auc: 0.9985 - val_f1sc: 0.9786 - val_fp: 37.0000 - val_fn: 146.0000 - val_tp: 4190.0000 - val_tn: 4299.0000\n",
      "Epoch 7/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9858Epoch 00006: val_loss improved from 0.05178 to 0.03655, saving model to model/model_hard_negative_thresh10_gen3_k3.h5\n",
      "400/400 [==============================] - 316s - loss: 0.0405 - acc: 0.9859 - val_loss: 0.0366 - val_acc: 0.9873 - val_auc: 0.9990 - val_f1sc: 0.9874 - val_fp: 69.0000 - val_fn: 41.0000 - val_tp: 4295.0000 - val_tn: 4267.0000\n",
      "Epoch 8/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9860Epoch 00007: val_loss did not improve\n",
      "400/400 [==============================] - 314s - loss: 0.0400 - acc: 0.9860 - val_loss: 0.0414 - val_acc: 0.9859 - val_auc: 0.9986 - val_f1sc: 0.9860 - val_fp: 83.0000 - val_fn: 39.0000 - val_tp: 4297.0000 - val_tn: 4253.0000\n",
      "Epoch 9/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9862Epoch 00008: val_loss did not improve\n",
      "400/400 [==============================] - 314s - loss: 0.0372 - acc: 0.9862 - val_loss: 0.0482 - val_acc: 0.9832 - val_auc: 0.9985 - val_f1sc: 0.9832 - val_fp: 74.0000 - val_fn: 72.0000 - val_tp: 4264.0000 - val_tn: 4262.0000\n",
      "Epoch 10/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9879Epoch 00009: val_loss did not improve\n",
      "400/400 [==============================] - 318s - loss: 0.0355 - acc: 0.9880 - val_loss: 0.0553 - val_acc: 0.9812 - val_auc: 0.9975 - val_f1sc: 0.9813 - val_fp: 101.0000 - val_fn: 62.0000 - val_tp: 4274.0000 - val_tn: 4235.0000\n",
      "Epoch 11/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9868Epoch 00010: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0379 - acc: 0.9869 - val_loss: 0.0512 - val_acc: 0.9836 - val_auc: 0.9978 - val_f1sc: 0.9837 - val_fp: 101.0000 - val_fn: 41.0000 - val_tp: 4295.0000 - val_tn: 4235.0000\n",
      "Epoch 12/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9856Epoch 00011: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0387 - acc: 0.9856 - val_loss: 0.0461 - val_acc: 0.9841 - val_auc: 0.9989 - val_f1sc: 0.9840 - val_fp: 34.0000 - val_fn: 104.0000 - val_tp: 4232.0000 - val_tn: 4302.0000\n",
      "Epoch 13/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9854Epoch 00012: val_loss did not improve\n",
      "400/400 [==============================] - 315s - loss: 0.0385 - acc: 0.9854 - val_loss: 0.0414 - val_acc: 0.9850 - val_auc: 0.9991 - val_f1sc: 0.9850 - val_fp: 56.0000 - val_fn: 74.0000 - val_tp: 4262.0000 - val_tn: 4280.0000\n",
      "Epoch 14/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9854Epoch 00013: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0420 - acc: 0.9854 - val_loss: 0.0438 - val_acc: 0.9830 - val_auc: 0.9989 - val_f1sc: 0.9830 - val_fp: 58.0000 - val_fn: 89.0000 - val_tp: 4247.0000 - val_tn: 4278.0000\n",
      "Epoch 15/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9770Epoch 00014: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0563 - acc: 0.9770 - val_loss: 0.0513 - val_acc: 0.9798 - val_auc: 0.9991 - val_f1sc: 0.9795 - val_fp: 24.0000 - val_fn: 151.0000 - val_tp: 4185.0000 - val_tn: 4312.0000\n",
      "Epoch 16/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9789Epoch 00015: val_loss did not improve\n",
      "400/400 [==============================] - 316s - loss: 0.0540 - acc: 0.9789 - val_loss: 0.0416 - val_acc: 0.9842 - val_auc: 0.9992 - val_f1sc: 0.9841 - val_fp: 33.0000 - val_fn: 104.0000 - val_tp: 4232.0000 - val_tn: 4303.0000\n",
      "Epoch 17/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9796Epoch 00016: val_loss did not improve\n",
      "400/400 [==============================] - 315s - loss: 0.0508 - acc: 0.9796 - val_loss: 0.0393 - val_acc: 0.9872 - val_auc: 0.9989 - val_f1sc: 0.9872 - val_fp: 39.0000 - val_fn: 72.0000 - val_tp: 4264.0000 - val_tn: 4297.0000\n",
      "Epoch 18/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9831Epoch 00017: val_loss did not improve\n",
      "400/400 [==============================] - 320s - loss: 0.0427 - acc: 0.9832 - val_loss: 0.0397 - val_acc: 0.9867 - val_auc: 0.9990 - val_f1sc: 0.9867 - val_fp: 39.0000 - val_fn: 76.0000 - val_tp: 4260.0000 - val_tn: 4297.0000\n",
      "Epoch 19/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9823Epoch 00018: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 317s - loss: 0.0442 - acc: 0.9823 - val_loss: 0.0447 - val_acc: 0.9824 - val_auc: 0.9989 - val_f1sc: 0.9822 - val_fp: 40.0000 - val_fn: 113.0000 - val_tp: 4223.0000 - val_tn: 4296.0000\n",
      "Epoch 20/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9840Epoch 00019: val_loss did not improve\n",
      "400/400 [==============================] - 314s - loss: 0.0392 - acc: 0.9840 - val_loss: 0.0479 - val_acc: 0.9848 - val_auc: 0.9988 - val_f1sc: 0.9847 - val_fp: 43.0000 - val_fn: 89.0000 - val_tp: 4247.0000 - val_tn: 4293.0000\n",
      "Epoch 21/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9904Epoch 00020: val_loss improved from 0.03655 to 0.03476, saving model to model/model_hard_negative_thresh10_gen3_k3.h5\n",
      "400/400 [==============================] - 312s - loss: 0.0273 - acc: 0.9904 - val_loss: 0.0348 - val_acc: 0.9878 - val_auc: 0.9991 - val_f1sc: 0.9877 - val_fp: 40.0000 - val_fn: 66.0000 - val_tp: 4270.0000 - val_tn: 4296.0000\n",
      "Epoch 22/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9906Epoch 00021: val_loss did not improve\n",
      "400/400 [==============================] - 310s - loss: 0.0266 - acc: 0.9906 - val_loss: 0.0352 - val_acc: 0.9872 - val_auc: 0.9992 - val_f1sc: 0.9872 - val_fp: 45.0000 - val_fn: 66.0000 - val_tp: 4270.0000 - val_tn: 4291.0000\n",
      "Epoch 23/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9909Epoch 00022: val_loss improved from 0.03476 to 0.03425, saving model to model/model_hard_negative_thresh10_gen3_k3.h5\n",
      "400/400 [==============================] - 310s - loss: 0.0270 - acc: 0.9909 - val_loss: 0.0342 - val_acc: 0.9881 - val_auc: 0.9992 - val_f1sc: 0.9881 - val_fp: 47.0000 - val_fn: 56.0000 - val_tp: 4280.0000 - val_tn: 4289.0000\n",
      "Epoch 24/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9908Epoch 00023: val_loss improved from 0.03425 to 0.03142, saving model to model/model_hard_negative_thresh10_gen3_k3.h5\n",
      "400/400 [==============================] - 310s - loss: 0.0270 - acc: 0.9908 - val_loss: 0.0314 - val_acc: 0.9894 - val_auc: 0.9993 - val_f1sc: 0.9894 - val_fp: 49.0000 - val_fn: 43.0000 - val_tp: 4293.0000 - val_tn: 4287.0000\n",
      "Epoch 25/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9923Epoch 00024: val_loss did not improve\n",
      "400/400 [==============================] - 313s - loss: 0.0223 - acc: 0.9923 - val_loss: 0.0341 - val_acc: 0.9893 - val_auc: 0.9992 - val_f1sc: 0.9893 - val_fp: 46.0000 - val_fn: 47.0000 - val_tp: 4289.0000 - val_tn: 4290.0000\n",
      "Epoch 26/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9921Epoch 00025: val_loss did not improve\n",
      "400/400 [==============================] - 309s - loss: 0.0247 - acc: 0.9921 - val_loss: 0.0333 - val_acc: 0.9895 - val_auc: 0.9990 - val_f1sc: 0.9895 - val_fp: 53.0000 - val_fn: 38.0000 - val_tp: 4298.0000 - val_tn: 4283.0000\n",
      "Epoch 27/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9908Epoch 00026: val_loss did not improve\n",
      "400/400 [==============================] - 313s - loss: 0.0252 - acc: 0.9909 - val_loss: 0.0366 - val_acc: 0.9892 - val_auc: 0.9991 - val_f1sc: 0.9891 - val_fp: 38.0000 - val_fn: 56.0000 - val_tp: 4280.0000 - val_tn: 4298.0000\n",
      "Epoch 28/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9910Epoch 00027: val_loss did not improve\n",
      "400/400 [==============================] - 311s - loss: 0.0249 - acc: 0.9910 - val_loss: 0.0338 - val_acc: 0.9892 - val_auc: 0.9992 - val_f1sc: 0.9892 - val_fp: 55.0000 - val_fn: 39.0000 - val_tp: 4297.0000 - val_tn: 4281.0000\n",
      "Epoch 29/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9915Epoch 00028: val_loss did not improve\n",
      "400/400 [==============================] - 314s - loss: 0.0238 - acc: 0.9915 - val_loss: 0.0349 - val_acc: 0.9888 - val_auc: 0.9993 - val_f1sc: 0.9888 - val_fp: 49.0000 - val_fn: 48.0000 - val_tp: 4288.0000 - val_tn: 4287.0000\n",
      "Epoch 30/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9916Epoch 00029: val_loss did not improve\n",
      "400/400 [==============================] - 313s - loss: 0.0258 - acc: 0.9916 - val_loss: 0.0353 - val_acc: 0.9871 - val_auc: 0.9992 - val_f1sc: 0.9870 - val_fp: 40.0000 - val_fn: 72.0000 - val_tp: 4264.0000 - val_tn: 4296.0000\n",
      "Epoch 31/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9928Epoch 00030: val_loss did not improve\n",
      "400/400 [==============================] - 313s - loss: 0.0212 - acc: 0.9928 - val_loss: 0.0376 - val_acc: 0.9875 - val_auc: 0.9990 - val_f1sc: 0.9875 - val_fp: 54.0000 - val_fn: 54.0000 - val_tp: 4282.0000 - val_tn: 4282.0000\n",
      "Epoch 32/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9909Epoch 00031: val_loss did not improve\n",
      "400/400 [==============================] - 311s - loss: 0.0238 - acc: 0.9909 - val_loss: 0.0361 - val_acc: 0.9880 - val_auc: 0.9991 - val_f1sc: 0.9880 - val_fp: 48.0000 - val_fn: 56.0000 - val_tp: 4280.0000 - val_tn: 4288.0000\n",
      "Epoch 33/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9927Epoch 00032: val_loss did not improve\n",
      "400/400 [==============================] - 312s - loss: 0.0207 - acc: 0.9927 - val_loss: 0.0343 - val_acc: 0.9896 - val_auc: 0.9993 - val_f1sc: 0.9896 - val_fp: 38.0000 - val_fn: 52.0000 - val_tp: 4284.0000 - val_tn: 4298.0000\n",
      "Epoch 34/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9879Epoch 00033: val_loss did not improve\n",
      "400/400 [==============================] - 312s - loss: 0.0311 - acc: 0.9879 - val_loss: 0.0434 - val_acc: 0.9866 - val_auc: 0.9991 - val_f1sc: 0.9865 - val_fp: 30.0000 - val_fn: 86.0000 - val_tp: 4250.0000 - val_tn: 4306.0000\n",
      "Epoch 35/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9832Epoch 00034: val_loss did not improve\n",
      "400/400 [==============================] - 310s - loss: 0.0427 - acc: 0.9832 - val_loss: 0.0424 - val_acc: 0.9845 - val_auc: 0.9991 - val_f1sc: 0.9844 - val_fp: 29.0000 - val_fn: 105.0000 - val_tp: 4231.0000 - val_tn: 4307.0000\n",
      "Epoch 36/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9838Epoch 00035: val_loss did not improve\n",
      "400/400 [==============================] - 312s - loss: 0.0405 - acc: 0.9838 - val_loss: 0.0411 - val_acc: 0.9860 - val_auc: 0.9993 - val_f1sc: 0.9859 - val_fp: 27.0000 - val_fn: 94.0000 - val_tp: 4242.0000 - val_tn: 4309.0000\n",
      "Epoch 37/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9844Epoch 00036: val_loss did not improve\n",
      "400/400 [==============================] - 314s - loss: 0.0396 - acc: 0.9844 - val_loss: 0.0428 - val_acc: 0.9857 - val_auc: 0.9992 - val_f1sc: 0.9856 - val_fp: 28.0000 - val_fn: 96.0000 - val_tp: 4240.0000 - val_tn: 4308.0000\n",
      "Epoch 38/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9877Epoch 00037: val_loss did not improve\n",
      "400/400 [==============================] - 313s - loss: 0.0322 - acc: 0.9877 - val_loss: 0.0434 - val_acc: 0.9860 - val_auc: 0.9991 - val_f1sc: 0.9859 - val_fp: 28.0000 - val_fn: 93.0000 - val_tp: 4243.0000 - val_tn: 4308.0000\n",
      "Epoch 39/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9873Epoch 00038: val_loss did not improve\n",
      "400/400 [==============================] - 317s - loss: 0.0328 - acc: 0.9873 - val_loss: 0.0441 - val_acc: 0.9860 - val_auc: 0.9992 - val_f1sc: 0.9859 - val_fp: 25.0000 - val_fn: 96.0000 - val_tp: 4240.0000 - val_tn: 4311.0000\n",
      "Epoch 40/150\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9897Epoch 00039: val_loss did not improve\n",
      "400/400 [==============================] - 313s - loss: 0.0272 - acc: 0.9897 - val_loss: 0.0361 - val_acc: 0.9875 - val_auc: 0.9993 - val_f1sc: 0.9875 - val_fp: 34.0000 - val_fn: 74.0000 - val_tp: 4262.0000 - val_tn: 4302.0000\n",
      "6.21448\n",
      "runung index: 0\n",
      "39.98738145828247\n",
      "runung index: 1\n",
      "37.1593496799469\n",
      "runung index: 2\n",
      "37.18761992454529\n",
      "runung index: 3\n",
      "37.04566764831543\n",
      "runung index: 4\n",
      "37.19725680351257\n",
      "runung index: 5\n",
      "37.10509133338928\n",
      "runung index: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.936277151107788\n",
      "doing training set prediction\n",
      "Generation3is the last one: done\n"
     ]
    }
   ],
   "source": [
    "### should implement hard-mining\n",
    "### for each generation, reload trained model, reset all parameter, change trainable data list\n",
    "glist = [1,2,3]\n",
    "for generation in glist:\n",
    "    print('We are now at generation' + str(generation))\n",
    "    K.clear_session()\n",
    "    if generation == 1:\n",
    "        \n",
    "        resnet_model = ResNet50(include_top=False, weights = \"imagenet\", input_shape = (200, 200, 3), pooling ='avg')\n",
    "        model = resnet_model_build(resnet_model, freeze_stage= fs, use_stage= us, acti = nn_activation)\n",
    "        model.summary()\n",
    "        opt = 'hard_negative_thresh10_gen' + str(generation) + '_k' + str(i_fold)\n",
    "        model_file_name = \"model/model_\" + opt + \".h5\"\n",
    "    else:\n",
    "        print('loading exist model: ' + model_file_name)\n",
    "        model = load_model(model_file_name) # load last generation model, update model_name after loading\n",
    "        opt = 'hard_negative_thresh10_gen' + str(generation) + '_k' + str(i_fold)\n",
    "        model_file_name = \"model/model_\" + opt + \".h5\"\n",
    "\n",
    "    lr = 0.00017\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6)\n",
    "    myoptimizer = Adam(lr= lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=myoptimizer, metrics=['acc'])\n",
    "\n",
    "    earlystop = EarlyStopping(monitor= 'val_loss', \n",
    "                                  min_delta= 0.0001, \n",
    "                                  patience= nb_epoch / 10, \n",
    "                                  verbose=0, mode='auto')\n",
    "    checkpoint = ModelCheckpoint(model_file_name,\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='auto')\n",
    "    loss_history = LossHistory()\n",
    "    \n",
    "    history_model = model.fit_generator(gen_data.train_generator(df_class0= train_nonC_list[generation], \n",
    "                                                                 df_class1=train_C,\n",
    "                                                                 class_0_ratio = 1,\n",
    "                                                                 class_1_ratio = 1,\n",
    "                                                                 bz = batch_size),\n",
    "                                            steps_per_epoch = n_batch,\n",
    "                                            epochs= nb_epoch,\n",
    "                                            validation_data=(x_val, y_val),\n",
    "                                            callbacks = [reduce_lr,\n",
    "                                                         loss_history, \n",
    "                                                         checkpoint, \n",
    "                                                         earlystop,\n",
    "                                                         LogAUC(), \n",
    "                                                         f1sc()  ])\n",
    "    # save training process\n",
    "    train_loss = history_model.history.get(\"loss\")\n",
    "    train_acc = history_model.history.get(\"acc\")\n",
    "\n",
    "    val_loss = history_model.history.get(\"val_loss\")\n",
    "    val_acc = history_model.history.get(\"val_acc\")\n",
    "    val_auc = history_model.history.get(\"val_auc\")\n",
    "    val_f1 = history_model.history.get('val_f1sc')\n",
    "    val_tp = np.array(history_model.history.get('val_tp')).astype('float32')\n",
    "    val_tn = np.array(history_model.history.get('val_tn')).astype('float32')\n",
    "    val_fp = np.array(history_model.history.get('val_fp')).astype('float32')\n",
    "    val_fn = np.array(history_model.history.get('val_fn')).astype('float32')\n",
    "\n",
    "    pd_tmp = pd.DataFrame({'train_loss': train_loss,\n",
    "                           'valid_loss': val_loss,\n",
    "                           'train_acc': train_acc,\n",
    "                           'valid_acc': val_acc,\n",
    "                           'valid_f1': val_f1,\n",
    "                           'valid_auc': val_auc,\n",
    "                           'valid_TP': val_tp,\n",
    "                           'valid_TN': val_tn,\n",
    "                           'valid_FP': val_fp,\n",
    "                           'valid_FN': val_fn})\n",
    "    pd_tmp.to_csv(opt + '_training_process_gen' + str(generation) + '.csv')\n",
    "\n",
    "    # make prediction\n",
    "    \n",
    "    pred_out = gen_data.model_predict_testing(model_name = model_file_name, \n",
    "                                              df_class0 = test_nonC, \n",
    "                                              df_class1 = test_C, \n",
    "                                              testing_batch_size= 12500)\n",
    "    pred_out.to_csv('res_csv/testing_' + opt + '.csv', index = False)\n",
    "    \n",
    "    ###\n",
    "    # do hard-negative-mining #\n",
    "    # random predict negative samples (non-copper)? or do all prediction\n",
    "    ###\n",
    "    print('doing training set prediction')\n",
    "    \n",
    "    if generation < glist[-1]:\n",
    "        mining = gen_data.model_predict_testing(model_name = model_file_name,\n",
    "                                                df_class0 = train_nonC_list[generation + 1],\n",
    "                                                df_class1 = train_C,\n",
    "                                                testing_batch_size = 12500)\n",
    "        # get \n",
    "        xxx = pd.concat([mining[(mining['y_true'] == 0) & (mining['y_pred'] >= 0.5) & (mining['y_pred'] < 0.95)],\n",
    "                 mining[(mining['y_true'] == 0) & (mining['y_pred'] >= 0.4) & (mining['y_pred'] < 0.5)].sample(frac = 0.8),\n",
    "                 mining[(mining['y_true'] == 0) & (mining['y_pred'] >= 0.3) & (mining['y_pred'] < 0.4)].sample(frac = 0.6),\n",
    "                 mining[(mining['y_true'] == 0) & (mining['y_pred'] >= 0.2) & (mining['y_pred'] < 0.3)].sample(frac = 0.4),\n",
    "                 mining[(mining['y_true'] == 0) & (mining['y_pred'] >= 0.0) & (mining['y_pred'] < 0.2)].sample(frac = 0.2)])\n",
    "        \n",
    "        train_nonC_list[generation + 1] = train_nonC_list[generation + 1][train_nonC_list[generation + 1].im_path.isin(list(xxx.png_name))]\n",
    "        \n",
    "        # if want to keep original data (rather than purely use new fold as training samples)\n",
    "        train_nonC_list[generation + 1] = pd.concat([train_nonC_list[generation], train_nonC_list[generation + 1]]) \n",
    "        \n",
    "        train_nonC_list[generation + 1].reset_index(drop = True)\n",
    "        print('Next generation nonC size: ' +  str(train_nonC_list[generation + 1].shape))\n",
    "    else:\n",
    "        print('Generation' + str(generation) + 'is the last one: done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
